{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkUf3qONQN/80aqPtEvjGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohsinposts/CS410-Project-YouTube-Controversy-Detector/blob/main/YouTube_Controversy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZpuABxchgku",
        "outputId": "01355cb2-3a2c-4d5c-937a-76ee46cf3951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-comment-downloader in /usr/local/lib/python3.12/dist-packages (0.1.78)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.12/dist-packages (from youtube-comment-downloader) (1.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube-comment-downloader) (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from dateparser->youtube-comment-downloader) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->youtube-comment-downloader) (2025.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser->youtube-comment-downloader) (2025.11.3)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->youtube-comment-downloader) (5.3.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-comment-downloader) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-comment-downloader) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-comment-downloader) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-comment-downloader) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7.0->dateparser->youtube-comment-downloader) (1.17.0)\n",
            "Requirement already satisfied: yt_dlp in /usr/local/lib/python3.12/dist-packages (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-comment-downloader\n",
        "!pip install yt_dlp\n",
        "!pip install transformers pandas matplotlib seaborn torch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from youtube_comment_downloader import YoutubeCommentDownloader, SORT_BY_POPULAR\n",
        "from yt_dlp import YoutubeDL\n",
        "from yt_dlp.utils import DownloadError\n",
        "from itertools import islice\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Loading sentiment analysis model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
        "\n",
        "LABELS = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "def get_recent_videos_from_channel(channel_url, max_videos=3):\n",
        "    ydl_opts = {\n",
        "        \"quiet\": True,\n",
        "        \"extract_flat\": True,\n",
        "        \"skip_download\": True,\n",
        "        \"no_warnings\": True,\n",
        "        \"extractor_args\": {\"youtube\": {\"player_client\": [\"android\"]}}\n",
        "    }\n",
        "\n",
        "    with YoutubeDL(ydl_opts) as ydl:\n",
        "        info = ydl.extract_info(channel_url, download=False)\n",
        "\n",
        "    entries = info.get(\"entries\", [])\n",
        "    if len(entries) > 0 and \"entries\" in entries[0]:\n",
        "        entries = entries[0][\"entries\"]\n",
        "\n",
        "    video_urls = [\n",
        "        f\"https://www.youtube.com/watch?v={video['id']}\"\n",
        "        for video in entries[:max_videos]\n",
        "        if \"id\" in video\n",
        "    ]\n",
        "\n",
        "    return video_urls\n",
        "\n",
        "def download_comments(video_url, limit=50):\n",
        "    downloader = YoutubeCommentDownloader()\n",
        "    comments = downloader.get_comments_from_url(video_url, sort_by=SORT_BY_POPULAR)\n",
        "    limited_comments = list(islice(comments, limit))\n",
        "    return limited_comments\n",
        "\n",
        "def get_video_title(video_url):\n",
        "    ydl_opts = {\n",
        "        \"quiet\": True,\n",
        "        \"skip_download\": True,\n",
        "        \"no_warnings\": True,\n",
        "        \"extractor_args\": {\"youtube\": {\"player_client\": [\"android\"]}}\n",
        "    }\n",
        "\n",
        "    with YoutubeDL(ydl_opts) as ydl:\n",
        "        try:\n",
        "            info = ydl.extract_info(video_url, download=False)\n",
        "            return info.get(\"title\", video_url)\n",
        "        except DownloadError as e:\n",
        "            print(f\"      ! Skipping video {video_url} (could not fetch title): {e}\")\n",
        "            return None\n",
        "\n",
        "def process_channels(channel_list, videos_per_channel=3, comment_limit=50):\n",
        "    results = {}\n",
        "    video_titles = {}\n",
        "    channel_names = {}\n",
        "\n",
        "    for channel in channel_list:\n",
        "        channel_name = channel.split(\"@\")[-1]\n",
        "        print(f\"\\nProcessing channel: {channel}\")\n",
        "\n",
        "        video_urls = get_recent_videos_from_channel(channel, max_videos=videos_per_channel)\n",
        "        print(f\"  ➤ Found {len(video_urls)} videos\")\n",
        "\n",
        "        channel_data = {}\n",
        "\n",
        "        for vid_url in video_urls:\n",
        "            video_title = get_video_title(vid_url)\n",
        "            if video_title is None:\n",
        "                continue\n",
        "\n",
        "            video_titles[vid_url] = video_title\n",
        "            channel_names[vid_url] = channel_name\n",
        "            print(f\"    ⤷ Downloading TOP comments for: {video_title}\")\n",
        "            comments = download_comments(vid_url, limit=comment_limit)\n",
        "            channel_data[vid_url] = comments\n",
        "            print(f\"       → {len(comments)} top comments collected\")\n",
        "\n",
        "        results[channel] = channel_data\n",
        "\n",
        "    return results, video_titles, channel_names\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"neutral\", 0.0, 0.0\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=1)[0].detach().numpy()\n",
        "\n",
        "    label_idx = np.argmax(probs)\n",
        "    label = LABELS[label_idx]\n",
        "    confidence = float(probs[label_idx])\n",
        "\n",
        "    numeric = -1 if label == \"negative\" else 1 if label == \"positive\" else 0\n",
        "\n",
        "    return label, confidence, numeric\n",
        "\n",
        "def flatten_comment_data(raw):\n",
        "    rows = []\n",
        "    for channel, videos in raw.items():\n",
        "        for video, comments in videos.items():\n",
        "            for c in comments:\n",
        "                rows.append({\n",
        "                    \"channel\": channel,\n",
        "                    \"video\": video,\n",
        "                    \"text\": c.get(\"text\", \"\"),\n",
        "                    \"likes\": c.get(\"votes\", 0),\n",
        "                })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def run_sentiment_pipeline(df):\n",
        "    print(f\"\\nAnalyzing sentiment for {len(df)} comments...\")\n",
        "    sentiments = df[\"text\"].apply(analyze_sentiment)\n",
        "    df[\"sentiment_label\"] = sentiments.apply(lambda x: x[0])\n",
        "    df[\"sentiment_confidence\"] = sentiments.apply(lambda x: x[1])\n",
        "    df[\"sentiment_score\"] = sentiments.apply(lambda x: x[2])\n",
        "    print(\"Sentiment analysis complete!\")\n",
        "    return df\n",
        "\n",
        "def categorize_video(row):\n",
        "    controversy = row[\"controversy\"]\n",
        "    avg_sentiment = row[\"avg_sentiment\"]\n",
        "\n",
        "    if controversy < 0.3:\n",
        "        if avg_sentiment > 0.5:\n",
        "            return \"Universally Positive\"\n",
        "        elif avg_sentiment < -0.5:\n",
        "            return \"Universally Negative\"\n",
        "        else:\n",
        "            return \"Neutral/Mild\"\n",
        "    else:\n",
        "        return \"Controversial/Mixed Opinions\"\n",
        "\n",
        "def compute_controversy(df, video_titles, channel_names):\n",
        "    sentiment_breakdown = df.groupby([\"video\", \"sentiment_label\"]).size().unstack(fill_value=0)\n",
        "    sentiment_breakdown = sentiment_breakdown.reset_index()\n",
        "\n",
        "    for col in [\"negative\", \"neutral\", \"positive\"]:\n",
        "        if col not in sentiment_breakdown.columns:\n",
        "            sentiment_breakdown[col] = 0\n",
        "\n",
        "    sentiment_breakdown[\"P\"] = sentiment_breakdown[\"positive\"]\n",
        "    sentiment_breakdown[\"N\"] = sentiment_breakdown[\"negative\"]\n",
        "    sentiment_breakdown[\"P_plus_N\"] = sentiment_breakdown[\"P\"] + sentiment_breakdown[\"N\"]\n",
        "\n",
        "    sentiment_breakdown[\"controversy\"] = sentiment_breakdown.apply(\n",
        "        lambda row: (4 * row[\"P\"] * row[\"N\"] / (row[\"P_plus_N\"] ** 2))\n",
        "        if row[\"P_plus_N\"] > 0 else 0,\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    avg_sentiment = df.groupby(\"video\")[\"sentiment_score\"].mean().reset_index()\n",
        "    avg_sentiment.columns = [\"video\", \"avg_sentiment\"]\n",
        "\n",
        "    grouped = sentiment_breakdown.merge(avg_sentiment, on=\"video\", how=\"left\")\n",
        "\n",
        "    grouped[\"video_title\"] = grouped[\"video\"].map(video_titles)\n",
        "    grouped[\"channel_name\"] = grouped[\"video\"].map(channel_names)\n",
        "    grouped[\"count\"] = grouped[\"positive\"] + grouped[\"neutral\"] + grouped[\"negative\"]\n",
        "    grouped[\"verdict\"] = grouped.apply(categorize_video, axis=1)\n",
        "\n",
        "    return grouped\n",
        "\n",
        "def print_formatted_stats(stats):\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"VIDEO CONTROVERSY ANALYSIS\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    stats_sorted = stats.sort_values([\"channel_name\", \"video_title\"])\n",
        "\n",
        "    current_channel = None\n",
        "    for idx, row in stats_sorted.iterrows():\n",
        "        if current_channel != row['channel_name']:\n",
        "            if current_channel is not None:\n",
        "                print()\n",
        "            current_channel = row['channel_name']\n",
        "            print(f\"\\n[{row['channel_name']}]\")\n",
        "\n",
        "        print(f\"  → {row['video_title']}\")\n",
        "        print(f\"    Controversy: {row['controversy']:.3f} | Avg Sentiment: {row['avg_sentiment']:.2f} | Verdict: {row['verdict']}\")\n",
        "        print(f\"    Sentiment: Positive={row['positive']} | Neutral={row['neutral']} | Negative={row['negative']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "\n",
        "def plot_sentiment_breakdown_by_controversy(stats, top_n=10):\n",
        "    top_videos = stats.nlargest(top_n, \"controversy\").copy()\n",
        "    top_videos = top_videos.sort_values(\"controversy\", ascending=True)\n",
        "    top_videos[\"display_name\"] = top_videos[\"channel_name\"] + \": \" + top_videos[\"video_title\"].str[:50]\n",
        "\n",
        "    total_comments = top_videos[\"positive\"] + top_videos[\"neutral\"] + top_videos[\"negative\"]\n",
        "    top_videos[\"neg_pct\"] = (top_videos[\"negative\"] / total_comments) * top_videos[\"controversy\"]\n",
        "    top_videos[\"neu_pct\"] = (top_videos[\"neutral\"] / total_comments) * top_videos[\"controversy\"]\n",
        "    top_videos[\"pos_pct\"] = (top_videos[\"positive\"] / total_comments) * top_videos[\"controversy\"]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "    y_pos = range(len(top_videos))\n",
        "\n",
        "    neg_bars = ax.barh(y_pos, top_videos[\"neg_pct\"], color=\"#d62728\", label=\"Negative\", alpha=0.85)\n",
        "    neu_bars = ax.barh(y_pos, top_videos[\"neu_pct\"], left=top_videos[\"neg_pct\"],\n",
        "                       color=\"#7f7f7f\", label=\"Neutral\", alpha=0.85)\n",
        "    pos_bars = ax.barh(y_pos, top_videos[\"pos_pct\"],\n",
        "                       left=top_videos[\"neg_pct\"] + top_videos[\"neu_pct\"],\n",
        "                       color=\"#2ca02c\", label=\"Positive\", alpha=0.85)\n",
        "\n",
        "    for i, (idx, row) in enumerate(top_videos.iterrows()):\n",
        "        ax.text(row[\"controversy\"] + 0.02, i,\n",
        "                f\"{row['controversy']:.3f}\",\n",
        "                va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "        counts_text = f\"({int(row['negative'])}/{int(row['neutral'])}/{int(row['positive'])})\"\n",
        "        ax.text(row[\"controversy\"]/2, i, counts_text,\n",
        "                va='center', ha='center', fontsize=8, color='white', fontweight='bold')\n",
        "\n",
        "    ax.set_yticks(y_pos)\n",
        "    ax.set_yticklabels(top_videos[\"display_name\"].values, fontsize=9)\n",
        "    ax.set_xlabel(\"Controversy Score (0=Unanimous, 1=Maximum Disagreement)\", fontsize=12, fontweight='bold')\n",
        "    ax.set_xlim(0, 1.1)\n",
        "    ax.set_title(f\"Top {top_n} Most Controversial Videos - Controversy Score with Sentiment Breakdown\",\n",
        "                 fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='lower right', fontsize=11, title=\"Sentiment (as % of bar)\")\n",
        "    ax.grid(axis=\"x\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_channel_controversy_scatter(df, channel_names):\n",
        "    video_stats = []\n",
        "    for video in df[\"video\"].unique():\n",
        "        video_df = df[df[\"video\"] == video]\n",
        "        pos = (video_df[\"sentiment_label\"] == \"positive\").sum()\n",
        "        neg = (video_df[\"sentiment_label\"] == \"negative\").sum()\n",
        "        non_neutral = pos + neg\n",
        "\n",
        "        if non_neutral > 0:\n",
        "            controversy = 4 * pos * neg / (non_neutral ** 2)\n",
        "        else:\n",
        "            controversy = 0\n",
        "\n",
        "        video_stats.append({\n",
        "            \"video\": video,\n",
        "            \"channel\": video_df[\"channel\"].iloc[0],\n",
        "            \"controversy\": controversy,\n",
        "            \"channel_name\": channel_names[video]\n",
        "        })\n",
        "\n",
        "    video_controversy = pd.DataFrame(video_stats)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    channels = sorted(video_controversy[\"channel_name\"].unique())\n",
        "    colors = plt.cm.Set3(range(len(channels)))\n",
        "\n",
        "    for i, channel in enumerate(channels):\n",
        "        channel_data = video_controversy[video_controversy[\"channel_name\"] == channel]\n",
        "        x_pos = [i] * len(channel_data)\n",
        "        ax.scatter(x_pos, channel_data[\"controversy\"], s=200, alpha=0.7,\n",
        "                  color=colors[i], label=channel, edgecolors='black', linewidth=1.5)\n",
        "\n",
        "    ax.set_xticks(range(len(channels)))\n",
        "    ax.set_xticklabels(channels, rotation=45, ha=\"right\", fontsize=11)\n",
        "    ax.set_ylabel(\"Controversy Score (Pos/Neg Disagreement)\", fontsize=12)\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.set_title(\"Video Controversy Distribution by Channel\", fontsize=14, fontweight='bold')\n",
        "    ax.grid(axis=\"y\", alpha=0.3)\n",
        "    ax.legend(loc='upper right', fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_channel_std_deviation(df, channel_names):\n",
        "    video_stats = []\n",
        "    for video in df[\"video\"].unique():\n",
        "        video_df = df[df[\"video\"] == video]\n",
        "        pos = (video_df[\"sentiment_label\"] == \"positive\").sum()\n",
        "        neg = (video_df[\"sentiment_label\"] == \"negative\").sum()\n",
        "        non_neutral = pos + neg\n",
        "\n",
        "        if non_neutral > 0:\n",
        "            controversy = 4 * pos * neg / (non_neutral ** 2)\n",
        "        else:\n",
        "            controversy = 0\n",
        "\n",
        "        video_stats.append({\n",
        "            \"video\": video,\n",
        "            \"channel_name\": channel_names[video],\n",
        "            \"controversy\": controversy\n",
        "        })\n",
        "\n",
        "    video_controversy = pd.DataFrame(video_stats)\n",
        "\n",
        "    channel_std = video_controversy.groupby(\"channel_name\")[\"controversy\"].std().reset_index()\n",
        "    channel_std.columns = [\"channel_name\", \"std_controversy\"]\n",
        "    channel_std = channel_std.sort_values(\"std_controversy\", ascending=False)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    bars = ax.bar(channel_std[\"channel_name\"], channel_std[\"std_controversy\"],\n",
        "                  color=\"steelblue\", alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "    for bar, val in zip(bars, channel_std[\"std_controversy\"]):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    ax.set_xlabel(\"Channel\", fontsize=12)\n",
        "    ax.set_ylabel(\"Standard Deviation of Video Controversy\", fontsize=12)\n",
        "    ax.set_title(\"Consistency of Controversy Across Videos by Channel\", fontsize=14, fontweight='bold')\n",
        "    ax.set_xticklabels(channel_std[\"channel_name\"], rotation=45, ha=\"right\", fontsize=11)\n",
        "    ax.grid(axis=\"y\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def run_full_analysis(data, video_titles, channel_names):\n",
        "    df = flatten_comment_data(data)\n",
        "    print(f\"\\nFlattened {len(df)} comments from {df['video'].nunique()} videos\")\n",
        "\n",
        "    df = run_sentiment_pipeline(df)\n",
        "\n",
        "    stats = compute_controversy(df, video_titles, channel_names)\n",
        "\n",
        "    print_formatted_stats(stats)\n",
        "\n",
        "    print(\"\\nGenerating visualizations...\")\n",
        "    plot_sentiment_breakdown_by_controversy(stats)\n",
        "    plot_channel_controversy_scatter(df, channel_names)\n",
        "    plot_channel_std_deviation(df, channel_names)\n",
        "\n",
        "    print(\"\\nTop 3 most controversial videos:\")\n",
        "    top3 = stats.nlargest(3, \"controversy\")[[\"channel_name\", \"video_title\", \"controversy\", \"avg_sentiment\", \"verdict\"]]\n",
        "    for idx, row in top3.iterrows():\n",
        "        print(f\"\\n  [{row['channel_name']}] {row['video_title']}\")\n",
        "        print(f\"    Controversy: {row['controversy']:.3f} | Verdict: {row['verdict']}\")\n",
        "\n",
        "    return df, stats\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCVW6BuBm5cE",
        "outputId": "43a50708-714d-4cfe-8ce0-2ffedd66d2b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sentiment analysis model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "channels = [\n",
        "    \"https://www.youtube.com/@PewDiePie\",\n",
        "    \"https://www.youtube.com/@AdinRoss\",\n",
        "    \"https://www.youtube.com/@OfficialFlagrant\",\n",
        "    \"https://www.youtube.com/@t3dotgg\",\n",
        "    \"https://www.youtube.com/@NancyPi\"\n",
        "]\n",
        "\n",
        "data, video_titles, channel_names = process_channels(channels, videos_per_channel=3, comment_limit=100)\n",
        "df, stats = run_full_analysis(data, video_titles, channel_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-JqNCpmgpYmR",
        "outputId": "923a0f9f-680e-45b4-d839-87e14351a376"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing channel: https://www.youtube.com/@PewDiePie\n",
            "  ➤ Found 3 videos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] gV_AnL2o3D0: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=gV_AnL2o3D0 (could not fetch title): ERROR: [youtube] gV_AnL2o3D0: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] qw4fDU18RcU: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=qw4fDU18RcU (could not fetch title): ERROR: [youtube] qw4fDU18RcU: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] OQUV6kEKwlk: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=OQUV6kEKwlk (could not fetch title): ERROR: [youtube] OQUV6kEKwlk: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
            "\n",
            "Processing channel: https://www.youtube.com/@AdinRoss\n",
            "  ➤ Found 3 videos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] rMWqVxHNprs: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=rMWqVxHNprs (could not fetch title): ERROR: [youtube] rMWqVxHNprs: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] TA9vFUOGY6E: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=TA9vFUOGY6E (could not fetch title): ERROR: [youtube] TA9vFUOGY6E: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] OeAnGVSO-9E: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=OeAnGVSO-9E (could not fetch title): ERROR: [youtube] OeAnGVSO-9E: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
            "\n",
            "Processing channel: https://www.youtube.com/@OfficialFlagrant\n",
            "  ➤ Found 3 videos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] buIc5vRqWOQ: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=buIc5vRqWOQ (could not fetch title): ERROR: [youtube] buIc5vRqWOQ: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] AeqP9VfFjUk: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=AeqP9VfFjUk (could not fetch title): ERROR: [youtube] AeqP9VfFjUk: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] XUUhR3TQT-I: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=XUUhR3TQT-I (could not fetch title): ERROR: [youtube] XUUhR3TQT-I: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
            "\n",
            "Processing channel: https://www.youtube.com/@t3dotgg\n",
            "  ➤ Found 3 videos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] dNviWH13dNY: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=dNviWH13dNY (could not fetch title): ERROR: [youtube] dNviWH13dNY: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] Dgm_Rr5JtaU: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=Dgm_Rr5JtaU (could not fetch title): ERROR: [youtube] Dgm_Rr5JtaU: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] UV9GqinedQ8: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=UV9GqinedQ8 (could not fetch title): ERROR: [youtube] UV9GqinedQ8: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
            "\n",
            "Processing channel: https://www.youtube.com/@NancyPi\n",
            "  ➤ Found 3 videos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] kxrkxLqW_TI: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=kxrkxLqW_TI (could not fetch title): ERROR: [youtube] kxrkxLqW_TI: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] i6kIjZA2UAI: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=i6kIjZA2UAI (could not fetch title): ERROR: [youtube] i6kIjZA2UAI: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] U_qp0isxQYU: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ! Skipping video https://www.youtube.com/watch?v=U_qp0isxQYU (could not fetch title): ERROR: [youtube] U_qp0isxQYU: Sign in to confirm you’re not a bot. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'video'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2240281876.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_titles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideos_per_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_full_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_titles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1862692534.py\u001b[0m in \u001b[0;36mrun_full_analysis\u001b[0;34m(data, video_titles, channel_names)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_full_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_titles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_comment_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nFlattened {len(df)} comments from {df['video'].nunique()} videos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_sentiment_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'video'"
          ]
        }
      ]
    }
  ]
}
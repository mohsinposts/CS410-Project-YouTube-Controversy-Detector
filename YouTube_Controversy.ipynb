{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZB0kGTqLTe3gdZe6t73SD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohsinposts/CS410-Project-YouTube-Controversy-Detector/blob/main/YouTube_Controversy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZpuABxchgku"
      },
      "outputs": [],
      "source": [
        "!pip install youtube-comment-downloader\n",
        "!pip install yt_dlp\n",
        "!pip install transformers pandas matplotlib seaborn torch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from youtube_comment_downloader import YoutubeCommentDownloader, SORT_BY_POPULAR\n",
        "from yt_dlp import YoutubeDL\n",
        "from yt_dlp.utils import DownloadError\n",
        "from itertools import islice\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Loading sentiment analysis model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
        "\n",
        "LABELS = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "def get_recent_videos_from_channel(channel_url, max_videos=3):\n",
        "    ydl_opts = {\n",
        "        \"quiet\": True,\n",
        "        \"extract_flat\": True,\n",
        "        \"skip_download\": True,\n",
        "        \"no_warnings\": True,\n",
        "        \"extractor_args\": {\"youtube\": {\"player_client\": [\"android\"]}}\n",
        "    }\n",
        "\n",
        "    with YoutubeDL(ydl_opts) as ydl:\n",
        "        info = ydl.extract_info(channel_url, download=False)\n",
        "\n",
        "    entries = info.get(\"entries\", [])\n",
        "    if len(entries) > 0 and \"entries\" in entries[0]:\n",
        "        entries = entries[0][\"entries\"]\n",
        "\n",
        "    video_urls = [\n",
        "        f\"https://www.youtube.com/watch?v={video['id']}\"\n",
        "        for video in entries[:max_videos]\n",
        "        if \"id\" in video\n",
        "    ]\n",
        "\n",
        "    return video_urls\n",
        "\n",
        "def download_comments(video_url, limit=50):\n",
        "    downloader = YoutubeCommentDownloader()\n",
        "    comments = downloader.get_comments_from_url(video_url, sort_by=SORT_BY_POPULAR)\n",
        "    limited_comments = list(islice(comments, limit))\n",
        "    return limited_comments\n",
        "\n",
        "def get_video_title(video_url):\n",
        "    ydl_opts = {\n",
        "        \"quiet\": True,\n",
        "        \"skip_download\": True,\n",
        "        \"no_warnings\": True,\n",
        "        \"extractor_args\": {\"youtube\": {\"player_client\": [\"android\"]}}\n",
        "    }\n",
        "\n",
        "    with YoutubeDL(ydl_opts) as ydl:\n",
        "        try:\n",
        "            info = ydl.extract_info(video_url, download=False)\n",
        "            return info.get(\"title\", video_url)\n",
        "        except DownloadError as e:\n",
        "            print(f\"      ! Skipping video {video_url} (could not fetch title): {e}\")\n",
        "            return None\n",
        "\n",
        "def process_channels(channel_list, videos_per_channel=3, comment_limit=50):\n",
        "    results = {}\n",
        "    video_titles = {}\n",
        "    channel_names = {}\n",
        "\n",
        "    for channel in channel_list:\n",
        "        channel_name = channel.split(\"@\")[-1]\n",
        "        print(f\"\\nProcessing channel: {channel}\")\n",
        "\n",
        "        video_urls = get_recent_videos_from_channel(channel, max_videos=videos_per_channel)\n",
        "        print(f\"  ➤ Found {len(video_urls)} videos\")\n",
        "\n",
        "        channel_data = {}\n",
        "\n",
        "        for vid_url in video_urls:\n",
        "            video_title = get_video_title(vid_url)\n",
        "            if video_title is None:\n",
        "                continue\n",
        "\n",
        "            video_titles[vid_url] = video_title\n",
        "            channel_names[vid_url] = channel_name\n",
        "            print(f\"    ⤷ Downloading TOP comments for: {video_title}\")\n",
        "            comments = download_comments(vid_url, limit=comment_limit)\n",
        "            channel_data[vid_url] = comments\n",
        "            print(f\"       → {len(comments)} top comments collected\")\n",
        "\n",
        "        results[channel] = channel_data\n",
        "\n",
        "    return results, video_titles, channel_names\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"neutral\", 0.0, 0.0\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=1)[0].detach().numpy()\n",
        "\n",
        "    label_idx = np.argmax(probs)\n",
        "    label = LABELS[label_idx]\n",
        "    confidence = float(probs[label_idx])\n",
        "\n",
        "    numeric = -1 if label == \"negative\" else 1 if label == \"positive\" else 0\n",
        "\n",
        "    return label, confidence, numeric\n",
        "\n",
        "def flatten_comment_data(raw):\n",
        "    rows = []\n",
        "    for channel, videos in raw.items():\n",
        "        for video, comments in videos.items():\n",
        "            for c in comments:\n",
        "                rows.append({\n",
        "                    \"channel\": channel,\n",
        "                    \"video\": video,\n",
        "                    \"text\": c.get(\"text\", \"\"),\n",
        "                    \"likes\": c.get(\"votes\", 0),\n",
        "                })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def run_sentiment_pipeline(df):\n",
        "    print(f\"\\nAnalyzing sentiment for {len(df)} comments...\")\n",
        "    sentiments = df[\"text\"].apply(analyze_sentiment)\n",
        "    df[\"sentiment_label\"] = sentiments.apply(lambda x: x[0])\n",
        "    df[\"sentiment_confidence\"] = sentiments.apply(lambda x: x[1])\n",
        "    df[\"sentiment_score\"] = sentiments.apply(lambda x: x[2])\n",
        "    print(\"Sentiment analysis complete!\")\n",
        "    return df\n",
        "\n",
        "def categorize_video(row):\n",
        "    controversy = row[\"controversy\"]\n",
        "\n",
        "    if controversy > 0:\n",
        "        return \"Controversial/Mixed Opinions\"\n",
        "    else:\n",
        "        return \"Not Controversial/One-Sided Opinions\"\n",
        "\n",
        "def compute_controversy(df, video_titles, channel_names):\n",
        "    sentiment_breakdown = df.groupby([\"video\", \"sentiment_label\"]).size().unstack(fill_value=0)\n",
        "    sentiment_breakdown = sentiment_breakdown.reset_index()\n",
        "\n",
        "    for col in [\"negative\", \"neutral\", \"positive\"]:\n",
        "        if col not in sentiment_breakdown.columns:\n",
        "            sentiment_breakdown[col] = 0\n",
        "\n",
        "    sentiment_breakdown[\"P\"] = sentiment_breakdown[\"positive\"]\n",
        "    sentiment_breakdown[\"N\"] = sentiment_breakdown[\"negative\"]\n",
        "\n",
        "    def calculate_controversy(row):\n",
        "        p_plus_n = row[\"P\"] + row[\"N\"]\n",
        "        if p_plus_n == 0:\n",
        "            return 0\n",
        "\n",
        "        p_ratio = row[\"P\"] / p_plus_n\n",
        "        n_ratio = row[\"N\"] / p_plus_n\n",
        "\n",
        "        min_threshold = 0.25\n",
        "        if p_ratio < min_threshold or n_ratio < min_threshold:\n",
        "            return 0\n",
        "\n",
        "        balance = 4 * row[\"P\"] * row[\"N\"] / (p_plus_n ** 2)\n",
        "\n",
        "        return balance\n",
        "\n",
        "    sentiment_breakdown[\"controversy\"] = sentiment_breakdown.apply(calculate_controversy, axis=1)\n",
        "\n",
        "    avg_sentiment = df.groupby(\"video\")[\"sentiment_score\"].mean().reset_index()\n",
        "    avg_sentiment.columns = [\"video\", \"avg_sentiment\"]\n",
        "\n",
        "    grouped = sentiment_breakdown.merge(avg_sentiment, on=\"video\", how=\"left\")\n",
        "\n",
        "    grouped[\"video_title\"] = grouped[\"video\"].map(video_titles)\n",
        "    grouped[\"channel_name\"] = grouped[\"video\"].map(channel_names)\n",
        "    grouped[\"count\"] = grouped[\"positive\"] + grouped[\"neutral\"] + grouped[\"negative\"]\n",
        "    grouped[\"verdict\"] = grouped.apply(categorize_video, axis=1)\n",
        "\n",
        "    return grouped\n",
        "\n",
        "def print_formatted_stats(stats):\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"VIDEO CONTROVERSY ANALYSIS\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    stats_sorted = stats.sort_values([\"channel_name\", \"video_title\"])\n",
        "\n",
        "    current_channel = None\n",
        "    for idx, row in stats_sorted.iterrows():\n",
        "        if current_channel != row['channel_name']:\n",
        "            if current_channel is not None:\n",
        "                print()\n",
        "            current_channel = row['channel_name']\n",
        "            print(f\"\\n[{row['channel_name']}]\")\n",
        "\n",
        "        print(f\"  → {row['video_title']}\")\n",
        "        print(f\"    Controversy: {row['controversy']:.3f} | Avg Sentiment: {row['avg_sentiment']:.2f} | Verdict: {row['verdict']}\")\n",
        "        print(f\"    Sentiment: Positive={row['positive']} | Neutral={row['neutral']} | Negative={row['negative']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "\n",
        "def plot_sentiment_breakdown_by_controversy(stats, top_n=10):\n",
        "    top_videos = stats.nlargest(top_n, \"controversy\").copy()\n",
        "    top_videos = top_videos.sort_values(\"controversy\", ascending=True)\n",
        "    top_videos[\"display_name\"] = top_videos[\"channel_name\"] + \": \" + top_videos[\"video_title\"].str[:50]\n",
        "\n",
        "    total_comments = top_videos[\"positive\"] + top_videos[\"neutral\"] + top_videos[\"negative\"]\n",
        "    top_videos[\"neg_pct\"] = (top_videos[\"negative\"] / total_comments) * top_videos[\"controversy\"]\n",
        "    top_videos[\"neu_pct\"] = (top_videos[\"neutral\"] / total_comments) * top_videos[\"controversy\"]\n",
        "    top_videos[\"pos_pct\"] = (top_videos[\"positive\"] / total_comments) * top_videos[\"controversy\"]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "    y_pos = range(len(top_videos))\n",
        "\n",
        "    neg_bars = ax.barh(y_pos, top_videos[\"neg_pct\"], color=\"#d62728\", label=\"Negative\", alpha=0.85)\n",
        "    neu_bars = ax.barh(y_pos, top_videos[\"neu_pct\"], left=top_videos[\"neg_pct\"],\n",
        "                       color=\"#7f7f7f\", label=\"Neutral\", alpha=0.85)\n",
        "    pos_bars = ax.barh(y_pos, top_videos[\"pos_pct\"],\n",
        "                       left=top_videos[\"neg_pct\"] + top_videos[\"neu_pct\"],\n",
        "                       color=\"#2ca02c\", label=\"Positive\", alpha=0.85)\n",
        "\n",
        "    for i, (idx, row) in enumerate(top_videos.iterrows()):\n",
        "        ax.text(row[\"controversy\"] + 0.02, i,\n",
        "                f\"{row['controversy']:.3f}\",\n",
        "                va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "        counts_text = f\"({int(row['negative'])}/{int(row['neutral'])}/{int(row['positive'])})\"\n",
        "        ax.text(row[\"controversy\"]/2, i, counts_text,\n",
        "                va='center', ha='center', fontsize=8, color='white', fontweight='bold')\n",
        "\n",
        "    ax.set_yticks(y_pos)\n",
        "    ax.set_yticklabels(top_videos[\"display_name\"].values, fontsize=9)\n",
        "    ax.set_xlabel(\"Controversy Score (0=Unanimous, 1=Maximum Disagreement)\", fontsize=12, fontweight='bold')\n",
        "    ax.set_xlim(0, 1.1)\n",
        "    ax.set_title(f\"Top {top_n} Most Controversial Videos - Controversy Score with Sentiment Breakdown\",\n",
        "                 fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='lower right', fontsize=11, title=\"Sentiment (as % of bar)\")\n",
        "    ax.grid(axis=\"x\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_channel_controversy_scatter(df, channel_names):\n",
        "    video_stats = []\n",
        "    for video in df[\"video\"].unique():\n",
        "        video_df = df[df[\"video\"] == video]\n",
        "        pos = (video_df[\"sentiment_label\"] == \"positive\").sum()\n",
        "        neg = (video_df[\"sentiment_label\"] == \"negative\").sum()\n",
        "        non_neutral = pos + neg\n",
        "\n",
        "        if non_neutral > 0:\n",
        "            controversy = 4 * pos * neg / (non_neutral ** 2)\n",
        "        else:\n",
        "            controversy = 0\n",
        "\n",
        "        video_stats.append({\n",
        "            \"video\": video,\n",
        "            \"channel\": video_df[\"channel\"].iloc[0],\n",
        "            \"controversy\": controversy,\n",
        "            \"channel_name\": channel_names[video]\n",
        "        })\n",
        "\n",
        "    video_controversy = pd.DataFrame(video_stats)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    channels = sorted(video_controversy[\"channel_name\"].unique())\n",
        "    colors = plt.cm.Set3(range(len(channels)))\n",
        "\n",
        "    for i, channel in enumerate(channels):\n",
        "        channel_data = video_controversy[video_controversy[\"channel_name\"] == channel]\n",
        "        x_pos = [i] * len(channel_data)\n",
        "        ax.scatter(x_pos, channel_data[\"controversy\"], s=200, alpha=0.7,\n",
        "                  color=colors[i], label=channel, edgecolors='black', linewidth=1.5)\n",
        "\n",
        "    ax.set_xticks(range(len(channels)))\n",
        "    ax.set_xticklabels(channels, rotation=45, ha=\"right\", fontsize=11)\n",
        "    ax.set_ylabel(\"Controversy Score (Pos/Neg Disagreement)\", fontsize=12)\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.set_title(\"Video Controversy Distribution by Channel\", fontsize=14, fontweight='bold')\n",
        "    ax.grid(axis=\"y\", alpha=0.3)\n",
        "    ax.legend(loc='upper right', fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_channel_avg_controversy(df, channel_names):\n",
        "    video_stats = []\n",
        "    for video in df[\"video\"].unique():\n",
        "        video_df = df[df[\"video\"] == video]\n",
        "        pos = (video_df[\"sentiment_label\"] == \"positive\").sum()\n",
        "        neg = (video_df[\"sentiment_label\"] == \"negative\").sum()\n",
        "        p_plus_n = pos + neg\n",
        "\n",
        "        if p_plus_n == 0:\n",
        "            controversy = 0\n",
        "        else:\n",
        "            p_ratio = pos / p_plus_n\n",
        "            n_ratio = neg / p_plus_n\n",
        "\n",
        "            min_threshold = 0.25\n",
        "            if p_ratio < min_threshold or n_ratio < min_threshold:\n",
        "                controversy = 0\n",
        "            else:\n",
        "                controversy = 4 * pos * neg / (p_plus_n ** 2)\n",
        "\n",
        "        video_stats.append({\n",
        "            \"video\": video,\n",
        "            \"channel_name\": channel_names[video],\n",
        "            \"controversy\": controversy\n",
        "        })\n",
        "\n",
        "    video_controversy = pd.DataFrame(video_stats)\n",
        "\n",
        "    channel_avg = video_controversy.groupby(\"channel_name\")[\"controversy\"].mean().reset_index()\n",
        "    channel_avg.columns = [\"channel_name\", \"avg_controversy\"]\n",
        "    channel_avg = channel_avg.sort_values(\"avg_controversy\", ascending=False)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    bars = ax.bar(channel_avg[\"channel_name\"], channel_avg[\"avg_controversy\"],\n",
        "                  color=\"steelblue\", alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "    for bar, val in zip(bars, channel_avg[\"avg_controversy\"]):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    ax.set_xlabel(\"Channel\", fontsize=12)\n",
        "    ax.set_ylabel(\"Average Controversy Score\", fontsize=12)\n",
        "    ax.set_title(\"Most Controversial Channels (Average Across Videos)\", fontsize=14, fontweight='bold')\n",
        "    ax.set_xticklabels(channel_avg[\"channel_name\"], rotation=45, ha=\"right\", fontsize=11)\n",
        "    ax.grid(axis=\"y\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def run_full_analysis(data, video_titles, channel_names):\n",
        "    df = flatten_comment_data(data)\n",
        "    print(f\"\\nFlattened {len(df)} comments from {df['video'].nunique()} videos\")\n",
        "\n",
        "    df = run_sentiment_pipeline(df)\n",
        "\n",
        "    stats = compute_controversy(df, video_titles, channel_names)\n",
        "\n",
        "    print_formatted_stats(stats)\n",
        "\n",
        "    print(\"\\nGenerating visualizations...\")\n",
        "    plot_sentiment_breakdown_by_controversy(stats)\n",
        "    plot_channel_controversy_scatter(df, channel_names)\n",
        "    plot_channel_avg_controversy(df, channel_names)\n",
        "\n",
        "    print(\"\\nTop 3 most controversial videos:\")\n",
        "    top3 = stats.nlargest(3, \"controversy\")[[\"channel_name\", \"video_title\", \"controversy\", \"avg_sentiment\", \"verdict\"]]\n",
        "    for idx, row in top3.iterrows():\n",
        "        print(f\"\\n  [{row['channel_name']}] {row['video_title']}\")\n",
        "        print(f\"    Controversy: {row['controversy']:.3f} | Verdict: {row['verdict']}\")\n",
        "\n",
        "    return df, stats"
      ],
      "metadata": {
        "id": "pCVW6BuBm5cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channels = [\n",
        "    \"https://www.youtube.com/@PewDiePie\",\n",
        "    \"https://www.youtube.com/@AdinRoss\",\n",
        "    \"https://www.youtube.com/@OfficialFlagrant\",\n",
        "    \"https://www.youtube.com/@t3dotgg\",\n",
        "    \"https://www.youtube.com/@NancyPi\"\n",
        "]\n",
        "\n",
        "data, video_titles, channel_names = process_channels(channels, videos_per_channel=3, comment_limit=100)\n",
        "df, stats = run_full_analysis(data, video_titles, channel_names)"
      ],
      "metadata": {
        "id": "-JqNCpmgpYmR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}